# =============================================================================
# CRAVE SEARCH API ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and update the values according to your environment

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# Main development database URL
# Format: postgresql://username:password@host:port/database
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/crave_search"

# Test database URL (separate database for testing isolation)
# This should point to a different database than DATABASE_URL
TEST_DATABASE_URL="postgresql://postgres:postgres@localhost:5432/crave_search_test"

# Database Connection Pool Configuration
DATABASE_CONNECTION_POOL_MAX=10          # Maximum connections in pool
DATABASE_CONNECTION_POOL_MIN=2           # Minimum connections in pool
DATABASE_CONNECTION_ACQUIRE_TIMEOUT=60000 # Timeout in ms to acquire connection
DATABASE_CONNECTION_IDLE_TIMEOUT=10000   # Timeout in ms before idle connection closes
DATABASE_CONNECTION_EVICT_INTERVAL=10000 # Interval in ms to check for idle connections
DATABASE_HANDLE_DISCONNECTS=true        # Auto-reconnect on disconnection

# Database Query Configuration
DATABASE_QUERY_TIMEOUT=30000             # Query timeout in milliseconds
DATABASE_RETRY_ATTEMPTS=3                # Number of retry attempts on failure
DATABASE_RETRY_DELAY=1000               # Base delay between retries in ms
DATABASE_RETRY_FACTOR=2.0               # Exponential backoff factor

# Database Performance Configuration
DATABASE_PREPARED_STATEMENTS=true        # Enable prepared statements for performance
DATABASE_LOGGING=true                   # Enable database query logging (dev only)
DATABASE_SLOW_QUERY_THRESHOLD=1000     # Log queries slower than this (ms)

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================
REDIS_HOST=localhost                    # Redis host
REDIS_PORT=6379                        # Redis port

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================
PORT=3000                              # API server port
NODE_ENV=development                   # Environment: development, test, staging, production

# =============================================================================
# REDDIT API CONFIGURATION
# =============================================================================
# Required for Reddit integration and content processing
# Get these from https://www.reddit.com/prefs/apps
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret
REDDIT_USERNAME=your_reddit_username
REDDIT_PASSWORD=your_reddit_password
REDDIT_USER_AGENT=CraveSearch/1.0.0

# =============================================================================
# GEMINI LLM API CONFIGURATION
# =============================================================================
# Required for content processing and entity resolution
# Get your API key from https://aistudio.google.com/app/apikey
LLM_API_KEY=your_google_gemini_api_key
LLM_MODEL=gemini-2.5-flash            # Gemini model: gemini-2.5-flash, gemini-2.5-pro
LLM_BASE_URL=https://generativelanguage.googleapis.com/v1beta  # Gemini API base URL
LLM_TIMEOUT=30000                     # Request timeout in milliseconds
LLM_MAX_TOKENS=4000                   # Maximum tokens in response
LLM_TEMPERATURE=0.1                   # Temperature for creativity (0.0-2.0)
LLM_TOP_P=0.95                        # Top-p for nucleus sampling (0.0-1.0)
LLM_TOP_K=40                          # Top-k for token selection
LLM_CANDIDATE_COUNT=1                 # Number of response candidates
LLM_THINKING_ENABLED=true             # Enable Gemini thinking capabilities
LLM_THINKING_BUDGET=0                 # Thinking budget (0 for no limit)

# =============================================================================
# GOOGLE PLACES API CONFIGURATION
# =============================================================================
# Required for restaurant data enrichment and location services
# Get your API key from https://console.cloud.google.com/google/maps-apis/
GOOGLE_PLACES_API_KEY=your_google_places_api_key
GOOGLE_PLACES_TIMEOUT=10000           # Request timeout in milliseconds
GOOGLE_PLACES_REQUESTS_PER_SECOND=50  # Rate limit for API requests
GOOGLE_PLACES_DEFAULT_RADIUS=5000     # Default search radius in meters
GOOGLE_PLACES_MAX_RETRIES=3           # Maximum retry attempts on failure
GOOGLE_PLACES_RETRY_DELAY=1000        # Base delay between retries in ms
GOOGLE_PLACES_RETRY_BACKOFF_FACTOR=2.0 # Exponential backoff factor

# =============================================================================
# JWT AUTHENTICATION CONFIGURATION
# =============================================================================
# Generate a secure secret for production: openssl rand -base64 32
JWT_SECRET=your_jwt_secret_key_change_in_production
JWT_EXPIRATION=7d                     # Token expiration time

# =============================================================================
# DEVELOPMENT AND TESTING NOTES
# =============================================================================
# 
# For Local Development:
# 1. Start PostgreSQL and Redis: pnpm docker:up
# 2. Create databases: 
#    - createdb crave_search
#    - createdb crave_search_test
# 3. Run migrations: pnpm db:migrate
# 4. Seed data: pnpm db:seed
# 
# For Testing:
# - Integration tests automatically use TEST_DATABASE_URL
# - Tests will set NODE_ENV=test automatically
# - Test database should be separate from development database
# 
# For Production:
# - Set strong JWT_SECRET
# - Use production database credentials
# - Set NODE_ENV=production
# - Configure proper connection pool sizes
# - Enable DATABASE_HANDLE_DISCONNECTS=true